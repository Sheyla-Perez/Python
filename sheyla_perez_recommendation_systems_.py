# -*- coding: utf-8 -*-
"""Sheyla_Perez_Recommendation_Systems_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tgJMQ5Bk1pweKWtMBEV6mErqNOlRgemd

# **Music Recommendation System**

## **Milestone 1**

## **Problem Definition**

**The context:** 

Music platforms like Spotify, Youtube uses different recommendation model to provide personalized suggestions to different users. 
**The objectives:** 

Build a recommendation system to recommend songs to customers bases on their previos rating for other songs.

**The key questions:** What are the key questions that need to be answered?<br>
**The problem formulation:** What are we trying to solve using data science?
How can we manage data by considering recommendation to user-to-user and user-to-song, taking into account there genre and other facts?

## **Data Dictionary**

The core data is the Taste Profile Subset released by the Echo Nest as part of the Million Song Dataset. There are two files in this dataset. The first file contains the details about the song id, titles, release, artist name, and the year of release. The second file contains the user id, song id, and the play count of users.

song_data

song_id - A unique id given to every song

title - Title of the song

Release - Name of the released album

Artist_name - Name of the artist 

year - Year of release

count_data

user _id - A unique id given to the user

song_id - A unique id given to the song

play_count - Number of times the song was played

## **Data Source**
http://millionsongdataset.com/

## **Important Notes**

- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken to get a feasible solution to the problem. Please note that this is just one way of doing this. **There can be other 'creative' ways to solve the problem, and we encourage you to feel free and explore them as an 'optional' exercise**. 

- In the notebook, there are markdown cells called Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.

- The naming convention for different variables can vary. **Please consider the code provided in this notebook as a sample code.**

- All the outputs in the notebook are just for reference and can be different if you follow a different approach.

- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques.

### **Importing Libraries and the Dataset**
"""

# Mounting the drive
from google.colab import drive
drive.mount('/content/drive')

# Used to ignore the warning given as output of the code
import warnings
warnings.filterwarnings('ignore')

# Basic libraries of python for numeric and dataframe computations
import numpy as np
import pandas as pd

# Basic library for data visualization
import matplotlib.pyplot as plt

# Slightly advanced library for data visualization
import seaborn as sns

# To compute the cosine similarity between two vectors
from sklearn.metrics.pairwise import cosine_similarity

# A dictionary output that does not raise a key error
from collections import defaultdict

# A performance metrics in sklearn
from sklearn.metrics import mean_squared_error

from sklearn import preprocessing

"""### **Load the dataset**"""

# Importing the datasets
count_df = pd.read_csv('/content/drive/MyDrive/count_data.csv')
song_df = pd.read_csv('/content/drive/MyDrive/song_data.csv')

from google.colab import drive
drive.mount('/content/drive')

"""### **Understanding the data by viewing a few observations**"""

# See top 10 records of count_df data
count_df.head(10)

# See top 10 records of song_df data
song_df.head(10)

"""### **Let us check the data types and and missing values of each column**"""

# See the info of the count_df data
count_df.info

# See the info of the song_df data
song_df.info

"""#### **Observations and Insights:
It shows 1,000,000 records and 5 colums

"""

# Left merge the count_df and song_df data on "song_id". Drop duplicates from song_df data simultaneously
result = count_df.merge(song_df, left_on='song_id', right_on='song_id').drop_duplicates(subset=['song_id'])
# Drop the column 'Unnamed: 0'
result = result.drop(columns=['Unnamed: 0'])
result

"""**Think About It:** As the user_id and song_id are encrypted. Can they be encoded to numeric features?"""

# Apply label encoding for "user_id" and "song_id"
label_encoder = preprocessing.LabelEncoder()
result['user_id'] = label_encoder.fit_transform(result['user_id'])
result['song_id'] = label_encoder.fit_transform(result['song_id'])
result

"""**Think About It:** As the data also contains users who have listened to very few songs and vice versa, is it required to filter the data so that it contains users who have listened to a good count of songs and vice versa?"""

# Get the column containing the users
users = result.user_id

# Create a dictionary from users to their number of songs
ratings_count = dict()

for user in users:
    # If we already have the user, just add 1 to their rating count
    if user in ratings_count:
        ratings_count[user] += 1
    
    # Otherwise, set their rating count to 1
    else:
        ratings_count[user] = 1

# We want our users to have listened at least 90 songs
RATINGS_CUTOFF = 90

# Create a list of users who need to be removed
remove_users = []

for user, num_ratings in ratings_count.items():
    
    if num_ratings < RATINGS_CUTOFF:
        remove_users.append(user)

result = result.loc[ ~ result.user_id.isin(remove_users)]
result

# Get the column containing the songs
songs = result.song_id

# Create a dictionary from songs to their number of users
ratings_count = dict()

for song in songs:
    # If we already have the song, just add 1 to their rating count
    if song in ratings_count:
        ratings_count[song] += 1
    
    # Otherwise, set their rating count to 1
    else:
        ratings_count[song] = 1

# We want our song to be listened by atleast 120 users to be considred
RATINGS_CUTOFF = 120

remove_songs = []

for song, num_ratings in ratings_count.items():
    if num_ratings >= RATINGS_CUTOFF:
        remove_songs.append(song)

result_final = result.loc[ ~ result.song_id.isin(remove_songs)]
result_final

# Drop records with play_count more than(>) 5

play_count_remove = []

for item, play_count in result_final.items():
    item
    if num_ratings > 5:
        play_count_remove.append(item)

result_final = result_final.loc[ ~ result_final.user_id.isin(play_count_remove)]
result_final

# Check the shape of the data
shape = result_final.shape
shape

"""## **Exploratory Data Analysis**

### **Let's check the total number of unique users, songs, artists in the data**

Total number of unique user id
"""

# Display total number of unique user_id
users = count_df['user_id'].unique()
len(users)

"""Total number of unique song id"""

# Display total number of unique song_id
songs = song_df['song_id'].unique()
len(songs)

"""Total number of unique artists"""

# Display total number of unique artists
Artist = song_df['artist_name'].unique()
len(Artist)

"""#### **Observations and Insights:

We can observe that Total number of unique song_id ar 999056 and  unique artist are 72665.

### **Let's find out about the most interacted songs and interacted users**

Most interacted songs
"""

result['song_id'].value_counts()

"""Most interacted users"""

result['user_id'].value_counts()

"""#### **Observations and Insights:

While comparing the rating of 'Most interacted users/songs' it shows six user describe the interaction.

Songs played in a year
"""

count_songs = result.groupby('year').count()['title']

count = pd.DataFrame(count_songs)

count.drop(count.index[0], inplace = True)

count.tail()

# Create the plot

# Set the figure size
plt.figure(figsize = (30, 10))

sns.barplot(x = count.index,
            y = 'title',
            data = count,
            estimator = np.median)

# Set the y label of the plot
plt.ylabel('number of titles played') 

# Show the plot
plt.show()

"""#### **Observations and Insights:

We observe that after tuning this data into barplot, the model performance has shown since 2000's "number of title played" has reached a high median (2007's).

**Think About It:** What other insights can be drawn using exploratory data analysis?

Maximize insight into the data/understand the data structure;
Visualize potential relationships (direction and magnitude) between exposure and outcome variables.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html '/content/Sheyla_Perez_Recommendation_Systems_.ipynb'

"""## **Proposed approach**

In this case study, we built recommendation systems using the core data from Million Song Dataset. They are as follows:

Song_data using song_id
Artist_name and unique users, songs, artist in the data set.

By going step by step in the exploratory data analysis: surprise library has been used. For these algorithms, grid search cross-validation is used to find the interaction user and songs for the data, and improve the performance of the model**.
"""